{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "with open('train.json') as data_file:    \n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'cuisine': u'greek',\n",
       " u'id': 10259,\n",
       " u'ingredients': [u'romaine lettuce',\n",
       "  u'black olives',\n",
       "  u'grape tomatoes',\n",
       "  u'garlic',\n",
       "  u'pepper',\n",
       "  u'purple onion',\n",
       "  u'seasoning',\n",
       "  u'garbanzo beans',\n",
       "  u'feta cheese crumbles']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greek\n"
     ]
    }
   ],
   "source": [
    "print data[0]['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now from here on I want to create a count matrix so that we can feed it directly to TF IDF</h3>\n",
    "\n",
    "<a href = \"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">click  for more details </a>\n",
    "\n",
    "<pre>\n",
    "also the count matrix will be of size (#of cusine , #of ingredient) and say an element at position (i,j) will tell us the count of the ingredient no. j in the cuisine no. i   \n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let me create a list of all ingredient, a list of all cuisines and a dictionary right now which contain the count of ingredient \n",
    "#i in cuisine j\n",
    "dict_cuisine_ingredient = {}\n",
    "all_cuisine = []\n",
    "all_ingredient = []\n",
    "\n",
    "for recipe in data:\n",
    "    \n",
    "    if recipe['cuisine'] not in dict_cuisine_ingredient:\n",
    "        dict_cuisine_ingredient[recipe['cuisine']] = {}\n",
    "        all_cuisine.append(recipe['cuisine'])\n",
    "    \n",
    "    for ingredient in recipe['ingredients']:\n",
    "        dict_cuisine_ingredient[recipe['cuisine']][ingredient] = dict_cuisine_ingredient[recipe['cuisine']].get(ingredient,0) + 1\n",
    "        all_ingredient.append(ingredient)\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Count of Cuisines and Ingredients </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_cuisine_ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#just want to have unique\n",
    "all_cuisine = list(set(all_cuisine)) \n",
    "all_ingredient = list(set(all_ingredient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "6714\n"
     ]
    }
   ],
   "source": [
    "print len(all_cuisine)\n",
    "print len(all_ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'irish', u'mexican', u'chinese', u'filipino', u'vietnamese', u'moroccan', u'brazilian', u'japanese', u'british', u'greek', u'indian', u'jamaican', u'french', u'spanish', u'russian', u'cajun_creole', u'thai', u'southern_us', u'korean', u'italian']\n"
     ]
    }
   ],
   "source": [
    "print all_cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'low-sodium fat-free chicken broth', u'sweetened coconut', u'baking chocolate', u'egg roll wrappers', u'bottled low sodium salsa', u'vegan parmesan cheese', u'clam sauce', u'mahlab', u'(10 oz.) frozen chopped spinach, thawed and squeezed dry', u'figs', u'caramels', u'broiler', u'jalapeno chilies', u'(15 oz.) refried beans', u'brioche buns', u'broccoli romanesco', u'flaked oats', u'anise extract', u'whole wheat pastry flour', u'ravva']\n"
     ]
    }
   ],
   "source": [
    "print all_ingredient[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now if we want to see how many ingredients are used in indian cuisine </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664\n"
     ]
    }
   ],
   "source": [
    "print len(dict_cuisine_ingredient['indian']) # a lot of ingredients here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now lets do the count matrix from the dictionary </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the rows and the columns will be based on all_cuisine and all_ingredient\n",
    "count_matrix = np.zeros((len(all_cuisine),len(all_ingredient)))\n",
    "\n",
    "for i,cuisine in enumerate(all_cuisine):\n",
    "    for j,ingredient in enumerate(all_ingredient):\n",
    "        count_matrix[i,j] = dict_cuisine_ingredient[cuisine].get(ingredient,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   1., ...,   0.,   0.,   2.],\n",
       "       [  4.,   0.,   0., ...,   0.,   1.,  52.],\n",
       "       [  1.,   1.,   0., ...,   0.,   0.,  29.],\n",
       "       ..., \n",
       "       [  8.,   0.,   0., ...,   0.,   0.,  17.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   4.],\n",
       "       [  4.,   0.,   1., ...,   0.,   1.,  85.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looks like it is a sparse matrix we can take its benefit\n",
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_matrix = sparse.csr_matrix(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Now lets do TF IDF </h2>\n",
    "<br>\n",
    "<a href =\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\"> more information here </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tf_idf = transformer.fit_transform(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x6714 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 29179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Again to matrix \n",
    "tf_idf_matrix = tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20L, 6714L)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets apply clustering on it </h3>\n",
    "<pre>\n",
    "It will be expensive to do clustering in 6714 dimensions so lets do PCA first and convert it into 2 dimensions \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 5)\n",
    "\n",
    "reduced_data = pca.fit_transform(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3190509 ,  0.39170113,  0.10008381, -0.03017281,  0.06326038],\n",
       "       [-0.07486998, -0.32682025,  0.05442174, -0.27504495, -0.15209605],\n",
       "       [ 0.56009452,  0.16113335, -0.24069736,  0.05060211, -0.07985692],\n",
       "       [ 0.20270626,  0.03607879,  0.05282143, -0.10025187, -0.11798547],\n",
       "       [ 0.56358491, -0.05305991,  0.40653846,  0.19919508,  0.0884989 ],\n",
       "       [-0.17645412, -0.40208961, -0.12582193, -0.06495178,  0.28841227],\n",
       "       [-0.09842421, -0.17693367,  0.11179003, -0.13459559, -0.2077101 ],\n",
       "       [ 0.46796668,  0.22767811, -0.39121186, -0.06937381,  0.15523455],\n",
       "       [-0.33068868,  0.4254544 ,  0.10836234, -0.01319504,  0.09759842],\n",
       "       [-0.25779666, -0.32178728, -0.1759282 ,  0.31458899,  0.07152844],\n",
       "       [-0.00186022, -0.21125909,  0.00524111, -0.46856591,  0.32072498],\n",
       "       [-0.02508152, -0.01287297,  0.02645654, -0.21063903, -0.16790973],\n",
       "       [-0.3306661 ,  0.16313439,  0.01846612,  0.20312366,  0.08064937],\n",
       "       [-0.25956645, -0.28793704, -0.10810813,  0.17797096,  0.00363937],\n",
       "       [-0.26445528,  0.30354212,  0.06308392, -0.03177679,  0.07755638],\n",
       "       [-0.18776996, -0.06947568, -0.03286485, -0.04373936, -0.43526013],\n",
       "       [ 0.57495852, -0.15102621,  0.47044345,  0.14393147,  0.0583977 ],\n",
       "       [-0.30543932,  0.35523236,  0.10245956, -0.00893466, -0.02965052],\n",
       "       [ 0.56046977,  0.14174293, -0.33704589,  0.0545344 , -0.09091047],\n",
       "       [-0.29765728, -0.19243587, -0.10849028,  0.30729492, -0.02412138]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_data  #now the whole thing goes from 20 X 6714 to 20 X 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 3,random_state = 0).fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cuisine.index('indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {(all_cuisine[i],kmeans.labels_[i]) for i in range(len(all_cuisine))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(u'brazilian', 0),\n",
       " (u'british', 1),\n",
       " (u'cajun_creole', 0),\n",
       " (u'chinese', 2),\n",
       " (u'filipino', 2),\n",
       " (u'french', 1),\n",
       " (u'greek', 0),\n",
       " (u'indian', 0),\n",
       " (u'irish', 1),\n",
       " (u'italian', 0),\n",
       " (u'jamaican', 0),\n",
       " (u'japanese', 2),\n",
       " (u'korean', 2),\n",
       " (u'mexican', 0),\n",
       " (u'moroccan', 0),\n",
       " (u'russian', 1),\n",
       " (u'southern_us', 1),\n",
       " (u'spanish', 0),\n",
       " (u'thai', 2),\n",
       " (u'vietnamese', 2)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "If we look at the above labels we can see that spanish,jamaican,mexican,indian which is mostly considered spicy is put in the same classification.\n",
    "\n",
    "Also the food such as Chinese,filipano,thai,vietnamese are very similar label 2.And so on \n",
    "</pre>\n",
    "\n",
    "A great kernel showing the same analysis with great visualization is\n",
    "<a href = \"https://www.kaggle.com/alonalevy/whats-cooking/cultural-diffusion-by-recipes\">shown here </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> More clustering - This time soft clustering </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now lets see some results from mixture model\n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = GMM(n_components = 3,random_state= 0).fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.77468776e-008,   9.99999982e-001,   1.43928959e-011],\n",
       "       [  9.99999952e-001,   4.39222469e-021,   4.76979501e-008],\n",
       "       [  1.18372137e-012,   3.96052407e-113,   1.00000000e+000],\n",
       "       [  1.97029199e-002,   2.03631961e-037,   9.80297080e-001],\n",
       "       [  2.31099249e-014,   5.42477616e-116,   1.00000000e+000],\n",
       "       [  9.99999998e-001,   6.45424546e-021,   2.09860028e-009],\n",
       "       [  9.99997556e-001,   5.26467573e-016,   2.44422883e-006],\n",
       "       [  2.32039430e-012,   8.38224542e-103,   1.00000000e+000],\n",
       "       [  5.90087636e-009,   9.99999994e-001,   7.60822012e-012],\n",
       "       [  9.99999998e-001,   1.76268850e-016,   2.12313789e-009],\n",
       "       [  9.99999999e-001,   2.68093592e-028,   1.20105336e-009],\n",
       "       [  9.99878924e-001,   8.71037806e-017,   1.21076199e-004],\n",
       "       [  1.53770126e-003,   9.98462296e-001,   2.46469718e-009],\n",
       "       [  9.99999991e-001,   6.54228249e-012,   9.21501206e-009],\n",
       "       [  2.22561980e-006,   9.99997774e-001,   8.69557127e-010],\n",
       "       [  9.99999997e-001,   1.71451410e-022,   2.96882104e-009],\n",
       "       [  1.71557130e-015,   1.21706388e-124,   1.00000000e+000],\n",
       "       [  2.46505489e-007,   9.99999753e-001,   1.64033552e-010],\n",
       "       [  1.64343907e-013,   1.19184192e-120,   1.00000000e+000],\n",
       "       [  9.99999997e-001,   2.42459376e-010,   2.64617867e-009]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we are directly getting the probabilty of the various classes.\n",
    "clusterer.predict_proba(reduced_data)\n",
    "# we are getting close to 1 probability because I am trying it on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python27]",
   "language": "python",
   "name": "conda-env-python27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
